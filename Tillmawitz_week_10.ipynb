{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eb5c4e8",
   "metadata": {},
   "source": [
    "# Data 620 Week 10: Document Classification\n",
    "Matthew Tillmawitz\n",
    "\n",
    "For this assignment we have been tasked with using the [Spambase](https://archive.ics.uci.edu/dataset/94/spambase) dataset from the University of California Irvine to perform document classification. The dataset consists of 4601 e-mails which have been labeled as either legitimate or spam with 57 pre-computed features. The original documents were not included in the dataset and appear to be unavailable, so additional feature engineering cannot be conducted. This is unfortunate, as it may have been interesting to use models such RoBERTa to generate embeddings from the documents and compare how models trained on these embeddings performed compared to the hand-crafted features. The feature ranges have already been documented and it has been confirmed there are no missing values for features, so exploratory data analysis will be skipped.\n",
    "\n",
    "The model types tested will be Logistic Regression, Random Forest, Adaboost, and a Neural Network. These models cover a range of model classes and demonstrate how different architectures perform on the problem. As the original study made use of a number of these model types as a baseline, we included Adaboost as a model type that was not already evaluated and will be changing the training metric. During development it was noted many models were achieving an AUC-ROC close to or even exceeding 0.99 indicating saturation of the metric. As a result, model selection will rely on average precision also known as AUC-PR. This metric can be useful when evaluating imbalanced datasets and targeting the minority class. We will compare the model performance we achieve to that of the baseline models to determine the efficacy of this method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f6b661d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, average_precision_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bf1872",
   "metadata": {},
   "source": [
    "Column names are provided in the documentation for the dataset and are copied over directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9f5202f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d',\n",
    "    'word_freq_our', 'word_freq_over', 'word_freq_remove', 'word_freq_internet',\n",
    "    'word_freq_order', 'word_freq_mail', 'word_freq_receive', 'word_freq_will',\n",
    "    'word_freq_people', 'word_freq_report', 'word_freq_addresses', 'word_freq_free',\n",
    "    'word_freq_business', 'word_freq_email', 'word_freq_you', 'word_freq_credit',\n",
    "    'word_freq_your', 'word_freq_font', 'word_freq_000', 'word_freq_money',\n",
    "    'word_freq_hp', 'word_freq_hpl', 'word_freq_george', 'word_freq_650',\n",
    "    'word_freq_lab', 'word_freq_labs', 'word_freq_telnet', 'word_freq_857',\n",
    "    'word_freq_data', 'word_freq_415', 'word_freq_85', 'word_freq_technology',\n",
    "    'word_freq_1999', 'word_freq_parts', 'word_freq_pm', 'word_freq_direct',\n",
    "    'word_freq_cs', 'word_freq_meeting', 'word_freq_original', 'word_freq_project',\n",
    "    'word_freq_re', 'word_freq_edu', 'word_freq_table', 'word_freq_conference',\n",
    "    'char_freq_;', 'char_freq_(', 'char_freq_[', 'char_freq_!',\n",
    "    'char_freq_$', 'char_freq_#', 'capital_run_length_average',\n",
    "    'capital_run_length_longest', 'capital_run_length_total', 'spam'\n",
    "]\n",
    "filepath = '/Users/matttillman/School/data_620/data/spambase.data'\n",
    "random_seed = 8675309"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ea4687",
   "metadata": {},
   "source": [
    "Checking the integrity and validity of the data, the number of samples and features matches the expected values from the dataset source. The numeric classifiers are 1 for spam and 0 for legitimate e-mails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8b33f2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 4601 samples, 57 features\n",
      "Class distribution:\n",
      "spam\n",
      "0    2788\n",
      "1    1813\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(filepath, header=None, names=columns)\n",
    "print(f\"Dataset loaded: {df.shape[0]} samples, {df.shape[1]-1} features\")\n",
    "print(f\"Class distribution:\\n{df['spam'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa237a9b",
   "metadata": {},
   "source": [
    "## Preparing the Splits\n",
    "\n",
    "The features have already been created as part of the dataset, and without the raw documents no further features can reasonably be generated. We will therefore conduct no additional feature engineering and instead move directly to generating splits. We will use the train/validate/test splitting method as is current best practice, with the test split containing 20% of the data and the validate set consisting of 16% of the data (20% of the non-test data). Stratified sampling is used to ensure the class imbalance is consistent in each of the splits. All features are continuous and have no missing values per the documentation, and we center and scale the features using scikit-learn's `RobustScaler`. This scaler was chosen as it is resilient to outliers due to using median and interquartile range instead of mean and variance in the relevant calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "765e4dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('spam', axis=1).values\n",
    "y = df['spam'].values\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed, stratify=y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.2, random_state=random_seed, stratify=y_temp)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9697b882",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "Logistic regression is conducted as a baseline. We evaluate different penalties using Lasso, Ridge, and ElasticNet. The best performing model uses Ridge regression and achieves an average precision of 0.90 on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6234a193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "\n",
      "Best parameters: {'l1_ratio': 0.25, 'penalty': 'l2'}\n",
      "Best cross-validation Average Precision: 0.9343\n",
      "Validation Average Precision: 0.8990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# l1_ratio only used when doing elasticnet, probably fitting way more models than I need, refactor\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'l1_ratio': [0.25, 0.5, 0.75]\n",
    "}\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000, random_state=random_seed, solver='saga')\n",
    "\n",
    "grid_search = GridSearchCV(lr, param_grid, cv=5, scoring='average_precision', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation Average Precision: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "val_score = average_precision_score(y_val, best_model.predict_proba(X_val)[:, 1])\n",
    "print(f\"Validation Average Precision: {val_score:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b51a9c",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "Random forest is a powerful ensemble method that performs well on a number of problems. After hyperparameter tuning, the best model achieves an average precision of 0.98 on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "aab644c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "\n",
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "Best cross-validation Average Precision: 0.9797\n",
      "Validation Average Precision: 0.9776\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=random_seed, n_jobs=-1)\n",
    "\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='average_precision', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation Average Precision: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "rf_model = grid_search.best_estimator_\n",
    "val_score = average_precision_score(y_val, rf_model.predict_proba(X_val)[:, 1])\n",
    "print(f\"Validation Average Precision: {val_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572622f0",
   "metadata": {},
   "source": [
    "## Adaboost\n",
    "\n",
    "Adaboost was not evaluated in the original study but is another strong ensemble method for classification in particular. While having long training times due to the sequential nature of the algorithm, it demonstrates strong performance with an average precision of 0.97 on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "798de8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "\n",
      "Best parameters: {'estimator__max_depth': 3, 'learning_rate': 0.5, 'n_estimators': 300}\n",
      "Best cross-validation Average Precision: 0.9793\n",
      "Validation Average Precision: 0.9717\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.5, 1.0],\n",
    "    'estimator__max_depth': [1, 2, 3]\n",
    "}\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(random_state=random_seed)\n",
    "ada = AdaBoostClassifier(estimator=base_estimator, random_state=random_seed)\n",
    "\n",
    "grid_search = GridSearchCV(ada, param_grid, cv=5, scoring='average_precision', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation Average Precision: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "ab_model = grid_search.best_estimator_\n",
    "val_score = average_precision_score(y_val, ab_model.predict_proba(X_val)[:, 1])\n",
    "print(f\"Validation Average Precision: {val_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3c7f17",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "Due to the complexity of the neural network, code is broken into functions. We experiment with a number of hyperparameters and layer sizes, with hidden layers ranging from [64, 32], [128, 64], and [128, 64, 32]. Dropout values were either 0.3 or 0.5 and learning rate was either 0.001 or 0.0001. These values allowed for reasonable ranges of variation to be addressed while still keeping training times managable on the available hardware. Models were trained over a maximum of 100 epochs with early stopping if models had not improved for 10 epochs. All model configurations stopped before reaching the full 100 epochs and thus reached convergence. The best performing model configuration was {'hidden_dims': [128, 64, 32], 'dropout': 0.5, 'lr': 0.001} and achieved an average precision of 0.96."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "275d6e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[64, 32], dropout=0.3):\n",
    "        super(SpamClassifier, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        layers.append(nn.Linear(prev_dim, 1))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "cddde4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(X_train, y_train, X_val, y_val, hidden_dims=[64, 32], dropout=0.3, lr=0.001, epochs=50, batch_size=64):\n",
    "    # Setting random seeds for reproducibility and to preserve my sanity when writing the report\n",
    "    np.random.seed(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Can probably do this conversion once, refactor\n",
    "    X_train_tensor = torch.FloatTensor(X_train)\n",
    "    y_train_tensor = torch.FloatTensor(y_train).unsqueeze(1)\n",
    "    X_val_tensor = torch.FloatTensor(X_val)\n",
    "    y_val_tensor = torch.FloatTensor(y_val).unsqueeze(1)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model = SpamClassifier(X_train.shape[1], hidden_dims, dropout)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_val_tensor)\n",
    "            val_loss = criterion(val_outputs, y_val_tensor).item()\n",
    "            val_losses.append(val_loss)\n",
    "            \n",
    "            val_preds = val_outputs.numpy().flatten()\n",
    "            val_ap = average_precision_score(y_val, val_preds)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, \"\n",
    "                  f\"Val Loss: {val_loss:.4f}, Val Average Precision: {val_ap:.4f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(f\"\\nBest validation loss: {best_val_loss:.4f}\\n\")\n",
    "    \n",
    "    return model, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6616922e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Config 1/9: {'hidden_dims': [64, 32], 'dropout': 0.3, 'lr': 0.001}\n",
      "\n",
      "======================================================================\n",
      "Epoch 10/100 - Train Loss: 0.1716, Val Loss: 0.1945, Val Average Precision: 0.9487\n",
      "Epoch 20/100 - Train Loss: 0.1410, Val Loss: 0.1816, Val Average Precision: 0.9517\n",
      "Epoch 30/100 - Train Loss: 0.1325, Val Loss: 0.1759, Val Average Precision: 0.9538\n",
      "Epoch 40/100 - Train Loss: 0.1389, Val Loss: 0.2963, Val Average Precision: 0.9518\n",
      "\n",
      "Early stopping at epoch 40\n",
      "\n",
      "Best validation loss: 0.1759\n",
      "\n",
      "Validation Average Precision: 0.9518\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Config 2/9: {'hidden_dims': [64, 32], 'dropout': 0.3, 'lr': 0.0001}\n",
      "\n",
      "======================================================================\n",
      "Epoch 10/100 - Train Loss: 0.4668, Val Loss: 0.4544, Val Average Precision: 0.8967\n",
      "Epoch 20/100 - Train Loss: 0.2744, Val Loss: 0.4115, Val Average Precision: 0.9118\n",
      "\n",
      "Early stopping at epoch 26\n",
      "\n",
      "Best validation loss: 0.3320\n",
      "\n",
      "Validation Average Precision: 0.9189\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Config 3/9: {'hidden_dims': [64, 32], 'dropout': 0.5, 'lr': 0.001}\n",
      "\n",
      "======================================================================\n",
      "Epoch 10/100 - Train Loss: 0.2043, Val Loss: 0.3282, Val Average Precision: 0.9392\n",
      "Epoch 20/100 - Train Loss: 0.1712, Val Loss: 0.3155, Val Average Precision: 0.9431\n",
      "\n",
      "Early stopping at epoch 27\n",
      "\n",
      "Best validation loss: 0.2022\n",
      "\n",
      "Validation Average Precision: 0.9469\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Config 4/9: {'hidden_dims': [128, 64], 'dropout': 0.3, 'lr': 0.001}\n",
      "\n",
      "======================================================================\n",
      "Epoch 10/100 - Train Loss: 0.1516, Val Loss: 0.3122, Val Average Precision: 0.9464\n",
      "Epoch 20/100 - Train Loss: 0.1272, Val Loss: 0.3035, Val Average Precision: 0.9498\n",
      "\n",
      "Early stopping at epoch 26\n",
      "\n",
      "Best validation loss: 0.1833\n",
      "\n",
      "Validation Average Precision: 0.9542\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Config 5/9: {'hidden_dims': [128, 64], 'dropout': 0.3, 'lr': 0.0001}\n",
      "\n",
      "======================================================================\n",
      "Epoch 10/100 - Train Loss: 0.3194, Val Loss: 0.3256, Val Average Precision: 0.9068\n",
      "Epoch 20/100 - Train Loss: 0.2367, Val Loss: 0.2535, Val Average Precision: 0.9267\n",
      "Epoch 30/100 - Train Loss: 0.2000, Val Loss: 0.3431, Val Average Precision: 0.9339\n",
      "Epoch 40/100 - Train Loss: 0.2127, Val Loss: 0.3319, Val Average Precision: 0.9376\n",
      "\n",
      "Early stopping at epoch 47\n",
      "\n",
      "Best validation loss: 0.2176\n",
      "\n",
      "Validation Average Precision: 0.9406\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Config 6/9: {'hidden_dims': [128, 64], 'dropout': 0.5, 'lr': 0.001}\n",
      "\n",
      "======================================================================\n",
      "Epoch 10/100 - Train Loss: 0.2087, Val Loss: 0.2031, Val Average Precision: 0.9466\n",
      "\n",
      "Early stopping at epoch 19\n",
      "\n",
      "Best validation loss: 0.1985\n",
      "\n",
      "Validation Average Precision: 0.9416\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Config 7/9: {'hidden_dims': [128, 64, 32], 'dropout': 0.3, 'lr': 0.001}\n",
      "\n",
      "======================================================================\n",
      "Epoch 10/100 - Train Loss: 0.1570, Val Loss: 0.1880, Val Average Precision: 0.9528\n",
      "Epoch 20/100 - Train Loss: 0.1242, Val Loss: 0.2964, Val Average Precision: 0.9524\n",
      "\n",
      "Early stopping at epoch 21\n",
      "\n",
      "Best validation loss: 0.1873\n",
      "\n",
      "Validation Average Precision: 0.9532\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Config 8/9: {'hidden_dims': [128, 64, 32], 'dropout': 0.3, 'lr': 0.0001}\n",
      "\n",
      "======================================================================\n",
      "Epoch 10/100 - Train Loss: 0.3198, Val Loss: 0.3256, Val Average Precision: 0.9000\n",
      "Epoch 20/100 - Train Loss: 0.2676, Val Loss: 0.3710, Val Average Precision: 0.9189\n",
      "\n",
      "Early stopping at epoch 20\n",
      "\n",
      "Best validation loss: 0.3256\n",
      "\n",
      "Validation Average Precision: 0.9189\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Config 9/9: {'hidden_dims': [128, 64, 32], 'dropout': 0.5, 'lr': 0.001}\n",
      "\n",
      "======================================================================\n",
      "Epoch 10/100 - Train Loss: 0.1917, Val Loss: 0.2105, Val Average Precision: 0.9404\n",
      "Epoch 20/100 - Train Loss: 0.1552, Val Loss: 0.1861, Val Average Precision: 0.9536\n",
      "Epoch 30/100 - Train Loss: 0.1302, Val Loss: 0.1750, Val Average Precision: 0.9586\n",
      "Epoch 40/100 - Train Loss: 0.1129, Val Loss: 0.2983, Val Average Precision: 0.9566\n",
      "\n",
      "Early stopping at epoch 40\n",
      "\n",
      "Best validation loss: 0.1750\n",
      "\n",
      "Validation Average Precision: 0.9566\n",
      "\n",
      "======================================================================\n",
      "Best configuration: {'hidden_dims': [128, 64, 32], 'dropout': 0.5, 'lr': 0.001}\n",
      "Best validation Average Precision: 0.9566\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "configs = [\n",
    "    {'hidden_dims': [64, 32], 'dropout': 0.3, 'lr': 0.001},\n",
    "    {'hidden_dims': [64, 32], 'dropout': 0.3, 'lr': 0.0001},\n",
    "    {'hidden_dims': [64, 32], 'dropout': 0.5, 'lr': 0.001},\n",
    "    {'hidden_dims': [128, 64], 'dropout': 0.3, 'lr': 0.001},\n",
    "    {'hidden_dims': [128, 64], 'dropout': 0.3, 'lr': 0.0001},\n",
    "    {'hidden_dims': [128, 64], 'dropout': 0.5, 'lr': 0.001},\n",
    "    {'hidden_dims': [128, 64, 32], 'dropout': 0.3, 'lr': 0.001},\n",
    "    {'hidden_dims': [128, 64, 32], 'dropout': 0.3, 'lr': 0.0001},\n",
    "    {'hidden_dims': [128, 64, 32], 'dropout': 0.5, 'lr': 0.001},\n",
    "]\n",
    "\n",
    "best_ap = 0\n",
    "best_config = None\n",
    "best_model = None\n",
    "\n",
    "for i, config in enumerate(configs):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"\\nConfig {i+1}/{len(configs)}: {config}\")\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    model, _, _ = train_neural_network(\n",
    "        X_train, y_train, X_val, y_val,\n",
    "        hidden_dims=config['hidden_dims'],\n",
    "        dropout=config['dropout'],\n",
    "        lr=config['lr'],\n",
    "        epochs=100\n",
    "    )\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_val_tensor = torch.FloatTensor(X_val)\n",
    "        val_preds = model(X_val_tensor).numpy().flatten()\n",
    "        val_ap = average_precision_score(y_val, val_preds)\n",
    "    \n",
    "    print(f\"Validation Average Precision: {val_ap:.4f}\")\n",
    "    \n",
    "    if val_ap > best_ap:\n",
    "        best_ap = val_ap\n",
    "        best_config = config\n",
    "        nn_model = model\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Best configuration: {best_config}\")\n",
    "print(f\"Best validation Average Precision: {best_ap:.4f}\")\n",
    "print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3cc034",
   "metadata": {},
   "source": [
    "## Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5e305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, model_name, is_neural_net=False):    \n",
    "    if is_neural_net:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_test_tensor = torch.FloatTensor(X_test)\n",
    "            y_pred_proba = model(X_test_tensor).numpy().flatten()\n",
    "            y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "    else:\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    decimal_places = 3\n",
    "    metrics = {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': round(accuracy_score(y_test, y_pred), decimal_places),\n",
    "        'Precision': round(precision_score(y_test, y_pred), decimal_places),\n",
    "        'Recall': round(recall_score(y_test, y_pred), decimal_places),\n",
    "        'F1': round(f1_score(y_test, y_pred), decimal_places),\n",
    "        'Avg Precision': round(average_precision_score(y_test, y_pred_proba), decimal_places)\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc102056",
   "metadata": {},
   "source": [
    "The models evaluated had a rather interesting heirarchy that was established, with the same ordering from most to least performant of Random Forest, Adaboost, Neural Network, and Logistic Regression by all metrics. It is unusual for a single model to be the most performant in every metric included, let alone for all models to fall into such a defined ordering. Additionally, both the Random Forest and Neural Network models performed better on the test set than the validation set in terms of average precision, indicating both models would generalize particularly well. When comparing to the values achieved by the baseline models included with the dataset, our Logistic Regression slightly underperforms by both accuracy and precision. Our Neural Network outperformed that of the baseline by both metrics, while the Random Forest model almost perfectly matched that of the baseline. As Adaboost was not included in the original study we will compare it to Xgboost as both models are very similar. In this comparison our Adaboost model matched the performance of the Xgboost model, however just barely falling in the bottom range of values for the model. For our purposes a model matched the performance of the baselines if it fell into the given ranges recorded for each model and over- or underperformed a baseline if it fell outside of the range. Overall, all models exhibited extremely good performance on the problem achieving scores of 0.9 or higher by all metrics, except in the case of Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "64e5dac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODEL COMPARISON TABLE\n",
      "======================================================================\n",
      "                     Accuracy  Precision  Recall     F1  Avg Precision\n",
      "Model                                                                 \n",
      "Logistic Regression     0.901      0.891   0.854  0.872          0.943\n",
      "Random Forest           0.952      0.954   0.923  0.938          0.981\n",
      "Adaboost                0.946      0.943   0.917  0.930          0.979\n",
      "Neural Network          0.940      0.935   0.912  0.923          0.975\n",
      "======================================================================\n",
      "BEST MODELS BY METRIC:\n",
      "======================================================================\n",
      "Accuracy       : Random Forest             (0.9520)\n",
      "Precision      : Random Forest             (0.9540)\n",
      "Recall         : Random Forest             (0.9230)\n",
      "F1             : Random Forest             (0.9380)\n",
      "Avg Precision  : Random Forest             (0.9810)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "metrics_lr = evaluate_model(lr_model, X_test, y_test, 'Logistic Regression')\n",
    "metrics_rf = evaluate_model(rf_model, X_test, y_test, 'Random Forest')\n",
    "metrics_ab = evaluate_model(ab_model, X_test, y_test, 'Adaboost')\n",
    "metrics_nn = evaluate_model(nn_model, X_test, y_test, 'Neural Network', is_neural_net=True)\n",
    "\n",
    "df_results = pd.DataFrame([metrics_lr, metrics_rf, metrics_ab, metrics_nn])\n",
    "df_results = df_results.set_index('Model')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MODEL COMPARISON TABLE\")\n",
    "print(\"=\" * 70)\n",
    "print(df_results.to_string())\n",
    "print(\"=\" * 70)\n",
    "\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1', 'Avg Precision']\n",
    "print(\"BEST MODELS BY METRIC:\")\n",
    "print(\"=\" * 70)\n",
    "for metric in metrics:\n",
    "    best_model = df_results[metric].idxmax()\n",
    "    best_value = df_results[metric].max()\n",
    "    print(f\"{metric:15s}: {best_model:25s} ({best_value:.4f})\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_620_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
