{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4ea7221",
   "metadata": {},
   "source": [
    "# Data 620 Project 3\n",
    "Matthew Tillmawitz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e682fa",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "For this assignment we will be building a classifier from the names corpus of the NLTK library to predict gender based on first names. Given the option of using decision trees, naive bayes, or maximum entropy models we chose to use a naive bayes classifier. Feature construction was based on the paper [\"The sound of gender – correlations of name phonology and gender across languages\"](https://www.degruyterbrill.com/document/doi/10.1515/ling-2020-0027/html?lang=en) which provides a detailed analysis of the characteristics of male and female names in Germanic and other languages. As English is a Germanic language and the names in the corpus are in English, we will be designing our features based strictly on the characteristics of the Germanic names. As a result, many of the features we will build will be categorical and likely sparse which will create a high-dimensional feature space well suited to naive bayes models. While the naive assumption of feature independence is not necessarily true given the tendency of certain letters to correlate (\"sh\", \"ph\", \"qu\", etc.), the correlation is likely not significant enough in the corpus to cause problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db9fe855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89196af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('names', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133a9e26",
   "metadata": {},
   "source": [
    "We can see there is an imbalance in the target class of roughly 1:2, which while not insignificant is also not large enough to require addressing. As such we will leave the data as is but be sure to preserve the class imbalance when splitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e6cc509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2943 male names (37.05% of names)\n",
      "There are 5001 female names (62.95% of names)\n"
     ]
    }
   ],
   "source": [
    "male_names = [word.lower() for word in names.words('male.txt')]\n",
    "female_names = [word.lower() for word in names.words('female.txt')]\n",
    "\n",
    "names_df = pd.DataFrame({\n",
    "    'name': male_names + female_names,\n",
    "    'gender': ['m'] * len(male_names) + ['f'] * len(female_names)\n",
    "    })\n",
    "\n",
    "print(f\"There are {len(male_names)} male names ({len(male_names) / len(names_df) * 100:.2f}% of names)\")\n",
    "print(f\"There are {len(female_names)} female names ({len(female_names) / len(names_df) * 100:.2f}% of names)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf4a805",
   "metadata": {},
   "source": [
    "It is important to know the length of the shortest names for the feature design portion, as logic will need to be added to avoid issues with names that are particularly short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbce96da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shortest name in the corpus has length: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"The shortest name in the corpus has length: {min(names_df['name'].str.len())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39a0d25",
   "metadata": {},
   "source": [
    "We will be splitting the data into training, dev-test, and testing samples with the dev-test and testing samples consisting of 500 names each and the rest of the data used for testing as is required by the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b3a188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_train, name_test_initial, gender_train, gender_test_initial = train_test_split(\n",
    "    names_df['name'],\n",
    "    names_df['gender'],\n",
    "    test_size=1000,\n",
    "    random_state=8675309,\n",
    "    stratify=names_df['gender']\n",
    ")\n",
    "\n",
    "name_test, name_dev_test, gender_test, gender_dev_test = train_test_split(\n",
    "    name_test_initial,\n",
    "    gender_test_initial,\n",
    "    test_size=0.5,\n",
    "    random_state=8675309\n",
    ")\n",
    "\n",
    "# Prevent indexing issues when zipping later\n",
    "name_train = name_train.tolist()\n",
    "gender_train = gender_train.tolist()\n",
    "name_dev_test = name_dev_test.tolist()\n",
    "gender_dev_test = gender_dev_test.tolist()\n",
    "name_test = name_test.tolist()\n",
    "gender_test = gender_test.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc1113d",
   "metadata": {},
   "source": [
    "## Initial Features\n",
    "\n",
    "For the initial feature set we will focus on one of the easier characteristics to detect programatically, the beginning and ending sounds of the names. The paper notes that ending vowel sounds and more front vowels indicate female names while final consonants and fewer front vowels indicate male names. To detect these factors, we will consider the first and last three letters of each name as they will most likely generate the first and last syllables or phonemes. In order to encapsulate the full \"sound\" of these parts, we will also look at the first and last letter as well as the first and last two letters. This will generate a large number of features based on the potential values which will be relatively sparsely populated, perfectly suited for our naive bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61378b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features need to be tuples in a list, function makes this easier than messing with a dataframe\n",
    "def features_base(name):\n",
    "    features = {}\n",
    "\n",
    "    features['last_letter'] = name[-1]\n",
    "    features['last_two'] = name[-2:]\n",
    "    features['last_three'] = name[-3:] if len(name) > 2 else name\n",
    "\n",
    "    features['first_letter'] = name[0]\n",
    "    features['first_two'] = name[:2]\n",
    "    features['first_three'] = name[:3] if len(name) > 2 else name\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6070206f",
   "metadata": {},
   "source": [
    "Considering the performance on the dev-test set, we can see our features perform extremely well with an accuracy of 0.856. We see a typical decay pattern in feature value looking at the most important features, with the combination of the last two letters appearing to be one of the best indicators of the gender of the name. This is somewhat surprising, as one may expect the last three letters to provide a better indication of the ending phoneme, however, this does not appear to be the case. Regardless, model performance is extremely good with little room for improvement. Nevertheless, we will attempt to enhance the model by including the additional features which the literature indicates may be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7e6dbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.856\n"
     ]
    }
   ],
   "source": [
    "base_train_set = [(features_base(name), gender) for name, gender in zip(name_train, gender_train)]\n",
    "base_classifier = nltk.NaiveBayesClassifier.train(base_train_set)\n",
    "\n",
    "base_dev_test_set = [(features_base(name), gender) for name, gender in zip(name_dev_test, gender_dev_test)]\n",
    "base_accuracy = nltk.classify.accuracy(base_classifier, base_dev_test_set)\n",
    "print(f\"Accuracy: {base_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0846954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                last_two = 'na'                f : m      =     94.1 : 1.0\n",
      "                last_two = 'la'                f : m      =     72.3 : 1.0\n",
      "                last_two = 'rt'                m : f      =     51.6 : 1.0\n",
      "                last_two = 'us'                m : f      =     38.3 : 1.0\n",
      "                last_two = 'ia'                f : m      =     37.7 : 1.0\n",
      "                last_two = 'sa'                f : m      =     33.4 : 1.0\n",
      "             last_letter = 'a'                 f : m      =     32.4 : 1.0\n",
      "                last_two = 'rd'                m : f      =     30.7 : 1.0\n",
      "             last_letter = 'k'                 m : f      =     29.3 : 1.0\n",
      "              last_three = 'ert'               m : f      =     28.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "base_classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d4ed53",
   "metadata": {},
   "source": [
    "## Additional Features\n",
    "\n",
    "We can easily include a proxy for the number of syllables in a name by using the number of letters, as they are likely interchangeable from a modeling perspective. The vowel ratio is similarly simple to include. The quality of the stressed vowel is a difficult feature to determine solely from the names without a phonetic transcription or other indicator, so we will not consider it for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "739e6922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def additional_features(name):\n",
    "    features = features_base(name)\n",
    "\n",
    "    features['length'] = len(name)\n",
    "\n",
    "    vowels = 'aeiou'\n",
    "    vowel_count = sum(1 for letter in name if letter in vowels)\n",
    "\n",
    "    features['vowel_ratio'] = vowel_count / len(name)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564bd68f",
   "metadata": {},
   "source": [
    "We can see that the additional features actually result in worse model performance, with an accuracy of 0.844. While not a large loss in performance, the additional features do not appear to have a positive effect on the model's ability to label the names and do not alter the top ten most informative features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a68461b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.844\n"
     ]
    }
   ],
   "source": [
    "additional_train_set = [(additional_features(name), gender) for name, gender in zip(name_train, gender_train)]\n",
    "additional_classifier = nltk.NaiveBayesClassifier.train(additional_train_set)\n",
    "\n",
    "additional_dev_test_set = [(additional_features(name), gender) for name, gender in zip(name_dev_test, gender_dev_test)]\n",
    "additional_accuracy = nltk.classify.accuracy(additional_classifier, additional_dev_test_set)\n",
    "print(f\"Accuracy: {additional_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20c9db83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                last_two = 'na'                f : m      =     94.1 : 1.0\n",
      "                last_two = 'la'                f : m      =     72.3 : 1.0\n",
      "                last_two = 'rt'                m : f      =     51.6 : 1.0\n",
      "                last_two = 'us'                m : f      =     38.3 : 1.0\n",
      "                last_two = 'ia'                f : m      =     37.7 : 1.0\n",
      "                last_two = 'sa'                f : m      =     33.4 : 1.0\n",
      "             last_letter = 'a'                 f : m      =     32.4 : 1.0\n",
      "                last_two = 'rd'                m : f      =     30.7 : 1.0\n",
      "             last_letter = 'k'                 m : f      =     29.3 : 1.0\n",
      "              last_three = 'ert'               m : f      =     28.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "additional_classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14eda1f",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Comparing the performance of both models on the test set, we get a rather interesting result. While the base features model sees a decrease in accuracy, as is expected, the model with additional features actually performs better on the test set than the dev-test set and outperforms the base features model. It is clear then that the additional features improve the generalizability of the model and reign in some of the overfitting caused by the base features. While this result might be counterintuitive based on the model performance on the dev-test data, they are inline with the conclusions of the research paper used as a reference for feature design. It is possible the model could benefit from some feature pruning of the base features to further address overfitting, however, as the model performance with the additional features is already very good and name spelling can have a very high degree of variance we will leave the model as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63c16122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base feature model accuracy: 0.832\n",
      "Additional feature model accuracy: 0.848\n"
     ]
    }
   ],
   "source": [
    "base_test_set = [(features_base(name), gender) for name, gender in zip(name_test, gender_test)]\n",
    "additional_test_set = [(additional_features(name), gender) for name, gender in zip(name_test, gender_test)]\n",
    "\n",
    "base_test_accuracy = nltk.classify.accuracy(base_classifier, base_test_set)\n",
    "additional_accuracy = nltk.classify.accuracy(additional_classifier, additional_test_set)\n",
    "\n",
    "print(f\"Base feature model accuracy: {base_test_accuracy}\")\n",
    "print(f\"Additional feature model accuracy: {additional_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32400bee",
   "metadata": {},
   "source": [
    "### Bibliography\n",
    "\n",
    "\n",
    "Ackermann, Tanja and Zimmer, Christian. \"The sound of gender – correlations of name phonology and gender across languages\" Linguistics, vol. 59, no. 4, 2021, pp. 1143-1177. https://doi.org/10.1515/ling-2020-0027\n",
    "                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_620_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
